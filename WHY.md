# The death spiral of AI-assisted product development

```
  "Build me a feature"
         â†“
  First result: impressive. 80% there.
         â†“
  "Fix this bug" â†’ fixed, but broke something else
         â†“
  "Fix that too" â†’ fixed, but subtle regression
         â†“
  "Be more specific" â†’ follows instructions literally, stops thinking
         â†“
  Reactive patching. Whack-a-mole. Going in circles.
         â†“
  Weird warts buried 3 steps back. Don't know what depends on them.
         â†“
  Ship it broken   â€” or â€”   throw it away and start over.
```

**Your instinct is to give more detail. It makes things worse.**

```
  What you try             What actually happens
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  More detailed prompts  â†’ Worse results. Follows instructions off a cliff.
  More iterations        â†’ More drift. Each fix breaks something else.
  More steering          â†’ Less coherence. You break its long-horizon planning.
```

**This is not a skill issue. It's a structural one.** And it hits hardest when you're building product â€” not patching bugs in existing code, but generating significant new greenfield territory where every decision compounds and there's no existing architecture to anchor against.

| | What's happening | The effect |
|---|---|---|
| ðŸ”„ **Context decay** | Every time you steer, you break its long-horizon planning | Loses the thread of what the system *should become*. Optimizes for what's on your screen right now. |
| ðŸ”¨ **Local optimization** | Bug â†’ fix bug. Test fails â†’ patch test. Repeat. | Whack-a-mole. Each swing makes the next mole harder to hit. Nobody asks "is this the right approach?" |
| ðŸŒŠ **Architecture drift** | No explicit phases. Everything is one long vibe session. | You optimize what you can see, not what the system needs. Decisions get buried in the diff. |
| ðŸª¤ **The specification trap** | More detailed instructions â†’ *worse* results | Detailed steps *replace* the agent's reasoning instead of informing it. Give it the gist and it uses judgment. Give it exact steps and it walks off a cliff. |

**This is the same problem that engineering teams solved decades ago with code review, design docs, and tech leads.** But those solutions assume human teams. You're working with AI agents that start fresh every session, don't remember what they decided yesterday, and are constitutionally inclined to be helpful rather than critical of their own work.

---

### âŒ The solutions people suggest don't help

| "Just use..." | Why it fails |
|---|---|
| **Jira / Linear** | Assumes persistent workers who remember. AI sessions are ephemeral. |
| **CI/CD pipelines** | Catches bugs *after* they're written. You need to prevent incoherent work from starting. |
| **Heavy agent frameworks** | 30 agents, custom vocabulary, mandatory installs. You wanted a tool, not a religion. |
| **Longer prompts** | *More detail â†’ worse results.* The agent follows your steps off a cliff instead of using judgment. |
| **"Just keep iterating"** | This IS the death spiral. Each iteration drifts further. |

---

### âœ… This framework is six independent tools

| | Tool | What it does | Without it |
|---|---|---|---|
| ðŸŒ± | **The Seed** | Engineering standards that persist across every session | Each session reinvents its own, or has none |
| ðŸŽ­ | **Perspectives** | Architect, reviewer, implementer â€” different lenses on the same work | One voice writes and approves its own code |
| ðŸ“‹ | **The PRD Format** | Tasks with outcomes and verification â€” "what done actually looks like" | "Done" = the code exists, not that it works |
| ðŸ’¾ | **The State System** | Context that accumulates across sessions â€” decisions, investigations, knowledge | Every session starts from zero |
| ðŸ§  | **Knowledge Convention** | How learnings persist so the next session is smarter | Hard-won insights evaporate when the session ends |
| ðŸŽ¯ | **The Orchestrator** | Enforces spec â†’ design â†’ implement â†’ review phases | Work collapses into one long vibe session |

> **Use all six. Or just one. Nothing requires anything else.**
>
> Want the Seed to improve any Claude session? Copy one file.
> Want PRDs + perspectives without the orchestrator? Three files.
> Want the full system running autonomously? Still just files in a directory.

---

## The deeper story

### Why "just use Claude Code" isn't enough

| Scope | The gap |
|---|---|
| ðŸ”¬ **Single session** | Great first result, but the refinement loop is where quality collapses. No separate reviewer perspective. It patches locally instead of reconsidering globally. Helpful when it should be critical. |
| ðŸ”— **Across sessions** | Context doesn't persist. Design rationale, ruled-out approaches, discovered constraints â€” gone. Next session re-makes decisions the last one already disproved. |
| ðŸ—ï¸ **Project scale** | Can't tell "code exists" from "actually works." Features accumulate without anyone verifying they cohere. |

This framework fills those gaps with lightweight structure â€” not process for the sake of process, but the minimum scaffolding that prevents the death spiral.

### ðŸ§ª The counterintuitive insight

After 160+ tasks of real AI-assisted development:

> **The more detailed the task specification, the worse the results.**

| Give Claude... | It does... |
|---|---|
| The gist â€” intent, context, the "why" | Uses judgment. Walks around obstacles. Makes senior-engineer decisions. |
| Exact step-by-step instructions | Follows them off a cliff. Forces step 3 to work instead of reconsidering. Optimizes against your spec, not reality. |

**The sweet spot: rich context + trust.** Enough to understand the intent. Enough freedom to execute with judgment. This is how a good tech lead manages a strong team â€” and how you should manage AI agents.

### ðŸš« What this is NOT

| | |
|---|---|
| Not a project management tool | No dashboards, burndowns, or sprint planning |
| Not an agent framework | No custom runtime, agent registry, or execution engine |
| Not a replacement for Claude Code | Makes it better at building real software. Doesn't compete with it. |
| Not all-or-nothing | The heaviest thing about it is choosing which parts you want |

### ðŸ‘‹ Who this is for

**You, if:**
- You're using AI to build *product* â€” new features, new systems, greenfield territory where decisions compound
- You've felt the excitement of the first AI result â†’ then the frustration of the refinement death spiral
- You've abandoned a project because the codebase became untrusted spaghetti
- You want to tech-lead AI agents like a good tech lead manages humans

**Not you, if:**
- Fixing bugs or making isolated changes to a large existing codebase (Claude Code is already great at this)
- Building one-off scripts or throwaway prototypes
- Large human team with process that already works
