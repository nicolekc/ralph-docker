{
  "name": "Framework Bootstrap",
  "description": "Get the Ralph framework to the point where it can build itself reliably: testable, self-installing, and following its own principles. This PRD is the first handoff from the founding design session to ongoing development.",
  "signoff": "full",
  "tasks": [
    {
      "id": "001",
      "description": "Establish testability foundations for the framework itself. The framework is unusual — it's prompt files, a skill, directory conventions, and an orchestrator. Apply the Novel Verification Methods pattern (see ralph-context/knowledge/novel-verification-methods.md): what are we verifying, why can't we verify it with existing tools, what would give us visibility? Key things to test: (1) Does /ralph correctly dispatch subagents? (dry-run or logging mode) (2) Do role prompts produce the expected kind of output? (3) Does the build cycle terminate correctly (circuit breaker, signoff gates)? (4) Does self-installation produce correct .ralph/ from framework/? Don't over-engineer the test infrastructure — apply the 'do inline vs spin off' table. But DO create enough foundation that subsequent tasks can be verified.",
      "outcome": "A verification approach exists for the framework's key mechanisms: orchestrator dispatch, role prompt behavior, build cycle flow, self-installation correctness",
      "verification": "At least one automated check exists for each key mechanism. The approach is documented so future tasks know how to add tests.",
      "dependencies": [],
      "status": "pending"
    },
    {
      "id": "002",
      "description": "Update install.sh for the new framework structure. The script currently copies old-style files (RALPH_PROMPT.md at root, etc.). It needs to: (1) copy framework/ contents into target's .ralph/, (2) create ralph-context/ and .ralph-tasks/ with bare structure, (3) copy .claude/skills/ (ralph, discover, refine), (4) handle self-installation (when target IS the ralph-docker repo, don't create circular copies). The existing PRD_REFINE.md content is valuable — preserve it in the framework. Backward compat with old layout is NOT required (only promptly used it, and we'll update promptly separately).",
      "outcome": "Running install.sh on a fresh project creates the full .ralph/, ralph-context/, .ralph-tasks/ structure with all framework files and skills",
      "verification": "Install into a temp directory. Verify all expected files exist. Verify .ralph/ matches framework/ contents. Verify the self-install case works.",
      "dependencies": [],
      "status": "pending"
    },
    {
      "id": "003",
      "description": "Test and refine the /ralph skill end-to-end. Run /ralph on a small test PRD (NOT this bootstrap PRD — create a dedicated 2-3 task test PRD). Verify: subagents dispatch correctly via Task tool, architect/implementer/reviewer cycle produces actual output, task state updates, .ralph-tasks/ gets populated, circuit breaker works if reviewer keeps rejecting, signoff gates work ('architecture' signoff stops after architect phase). Fix issues discovered.",
      "outcome": "/ralph can be invoked, dispatches subagents, progresses through the build cycle, and handles both happy path and circuit breaker",
      "verification": "Successfully complete at least one task from a test PRD using /ralph. Also trigger a circuit breaker and a signoff gate to verify they work.",
      "dependencies": ["001", "002"],
      "status": "pending"
    },
    {
      "id": "004",
      "description": "Investigation: AGENTS.md pattern — right balance for per-directory knowledge. Research how different ralph/claude implementations handle AGENTS.md (per-directory hint files). Some are too liberal (write noise after every change), some too conservative (never write anything). Investigate: what triggers a write? what content is useful vs noise? how to prevent staleness? Produce findings in .ralph-tasks/001-bootstrap/004/ with a recommendation. NON-CODE DELIVERABLE — needs human review.",
      "outcome": "A findings document with concrete recommendations for when and what to write to AGENTS.md files",
      "verification": "Document exists, covers the noise-vs-knowledge tradeoff, includes a concrete recommendation",
      "dependencies": [],
      "status": "pending"
    },
    {
      "id": "005",
      "description": "Investigation: principle adherence hardening. The design principles are written but there's a risk new sessions won't feel their weight (see ralph-context/knowledge/principle-adherence-risks.md). Investigate: can we test for principle adherence? Can we increase principle 'weight' without becoming prescriptive? Is there an experiment we can run (e.g., give a deliberately over-specified task and see if the AI pushes back)? Produce findings with specific recommendations. NON-CODE DELIVERABLE — needs human review.",
      "outcome": "Concrete recommendations for ensuring principle adherence — through testing, review checklists, seed improvements, or other means",
      "verification": "Document exists with actionable recommendations. At least one is implementable in a subsequent task.",
      "dependencies": [],
      "status": "pending"
    },
    {
      "id": "006",
      "description": "Integrate PRD_REFINE.md wisdom into the framework. The existing prds/PRD_REFINE.md contains hard-won insights: implementer trust balance, specification-creativity balance, concrete examples with tentative language, investigation task patterns, acceptance criteria quality. Split appropriately between an enhanced spec-reviewer role and a PRD authoring process. Don't lose content — it's battle-tested from 160+ Promptly tasks.",
      "outcome": "PRD_REFINE.md insights are in the framework (enhanced spec-reviewer and/or process doc). /refine skill references the framework's version.",
      "verification": "/refine skill works. Key insights (implementer trust, tentative language, investigation tasks) are preserved and findable.",
      "dependencies": ["002"],
      "status": "pending"
    },
    {
      "id": "007",
      "description": "Adapt Docker infrastructure for multi-repo. Current ralph-start.sh assumes one container = one repo. See .ralph-tasks/001-bootstrap/003/docker-multi-repo.md for design context. Keep it simple. Also document multi-level installation pattern (ralph-docker installed alongside target projects in Docker).",
      "outcome": "ralph-start.sh supports multiple projects. README documents multi-repo setup.",
      "verification": "Start container with two project directories. Both accessible, git works in each.",
      "dependencies": [],
      "status": "pending"
    },
    {
      "id": "008",
      "description": "Create the 6 standalone design docs for the framework's independent systems: (1) The Seed, (2) The Knowledge Convention, (3) The PRD Format, (4) The State System, (5) Role Definitions, (6) The Orchestrator Pattern. Each ~1 page in ralph-context/designs/. These explain what, why, which principles, and how each composes with the others.",
      "outcome": "6 design docs, each self-contained, each traceable to design principles",
      "verification": "Each under 2 pages. Each references at least one principle. No doc requires another to make sense.",
      "dependencies": [],
      "status": "pending"
    },
    {
      "id": "009",
      "description": "Investigation: human inbox mechanism. When ralph produces non-code deliverables (investigations, designs, architecture) that need human review, how does the human know where to look and what to review? Current 'needs_human_review' status is necessary but not sufficient. Research approaches: summary file, specific directory, PRD status integration. NON-CODE DELIVERABLE — needs human review.",
      "outcome": "A concrete design for how non-code deliverables surface to the human",
      "verification": "Document exists with a recommended approach. Simple enough to implement in one follow-up task.",
      "dependencies": [],
      "status": "pending"
    },
    {
      "id": "010",
      "description": "Adapt additional role prompts from open-source frameworks. Focus on Gas Town (MIT) for engineering quality. See .ralph-tasks/001-bootstrap/004/role-adaptation-notes.md. Consider: systematic debugger, investigator role, design review panel process. Only add what we'd actually use soon — not speculatively.",
      "outcome": "1-2 new role prompts or processes that add genuine capability",
      "verification": "Concise (~1 page), follow P2/P8, work standalone, don't duplicate existing roles",
      "dependencies": ["005"],
      "status": "pending"
    }
  ]
}
